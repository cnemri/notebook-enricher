{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aca38c7",
   "metadata": {},
   "source": [
    "# Iris Dataset Classification with Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bdbf56",
   "metadata": {},
   "source": [
    "This notebook performs data analysis and logistic regression modeling on the Iris dataset. It starts with data loading, exploration, and visualization, followed by model training and evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e0086",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Import Libraries](#import-libraries)\n",
    "2. [Load Data](#load-data)\n",
    "3. [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-(eda))\n",
    "4. [Data Visualization](#data-visualization)\n",
    "5. [Data Preprocessing](#data-preprocessing)\n",
    "6. [Model Training](#model-training)\n",
    "7. [Model Evaluation](#model-evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae28bd15",
   "metadata": {},
   "source": [
    "## Importing Necessary Tools\n",
    "\n",
    "This section sets up the environment by importing the required libraries for our analysis.  We'll be using:\n",
    "\n",
    "*   **pandas:** For data manipulation and analysis.  It provides data structures like DataFrames that make working with tabular data easier.\n",
    "*   **seaborn and matplotlib.pyplot:**  These libraries are used for data visualization. Seaborn builds on top of matplotlib to create statistically informative and visually appealing plots.\n",
    "*   **scikit-learn:** This powerful library provides tools for machine learning tasks. We import specific modules for splitting data (`train_test_split`), building a logistic regression model (`LogisticRegression`), and evaluating model performance (`accuracy_score`).  These tools will be essential in building and evaluating our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d405619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6aefe",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652c433",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Loading the Iris Data\n",
    "\n",
    "This section sets the stage for our analysis by loading the Iris dataset.  The data, stored in a CSV file named `iris.csv`, is read into a pandas DataFrame, a powerful structure for organizing and manipulating data.  This DataFrame, named `df`, becomes the central object holding our Iris data for subsequent exploration and model building.  This efficient loading process allows us to quickly access and utilize the information contained within the dataset.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f54227",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e24c690",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "This section kicks off the analysis by examining the Iris dataset to understand its structure and characteristics.  We use several methods to get a quick overview of the data.  First, `df.head()` shows the first few rows of the dataset, allowing a peek at the actual data values.  Then, `df.info()` provides a summary of the dataset, including the data types of each column (e.g., numerical, categorical) and whether there are any missing values. Finally, `df.describe()` calculates descriptive statistics like mean, standard deviation, and quartiles for the numerical columns. These methods together provide a foundational understanding of the dataset before we move on to visualization and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a527180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f634cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349d91a",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b22e70",
   "metadata": {},
   "source": [
    "## Visualizing Iris Features\n",
    "\n",
    "This section explores the relationships between different Iris flower features and how these relate to the species.  We use visual tools to gain insights into these relationships.\n",
    "\n",
    "*   **Pairplots:**  A pairplot helps visualize the relationships between all possible pairs of numerical features.  By coloring the points according to the Iris species, we can visually identify patterns and correlations specific to each species. This allows us to see how features might cluster or separate different species.\n",
    "*   **Boxplots:** We use a boxplot to compare the distribution of sepal length for each Iris species. This visualization helps us understand the typical range of sepal lengths and identify any significant differences between the species based on this feature.  Boxplots can reveal variations and potential outliers within each species group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89607568",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='species', y='sepal_length', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3435fcc4",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e675d28",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "This section prepares the data for the machine learning model.  We separate the dataset into features (X) and the target variable (y), which is the species of Iris flower we aim to predict. Then, we split the data into training and testing sets to evaluate the model's performance on unseen data.  This ensures that the model learns general patterns from the training data and doesn't simply memorize it.  The `random_state` ensures consistent splitting for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c12f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267cadd",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa1ee4",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "This section trains a logistic regression model to predict the iris species.  A logistic regression model is chosen because the target variable, 'species', is categorical. This model learns the relationships between the features (sepal length, sepal width, petal length, and petal width) and the target variable. The `fit` function trains the model by adjusting its internal parameters to minimize prediction errors on the training data.  This trained model is then used in the next section to make predictions on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae637957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec554281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8a877",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffafcb0",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Having trained our logistic regression model, we now assess its predictive capabilities on the unseen test data.  This evaluation helps us understand how well the model generalizes to new data and provides a measure of its real-world performance. We use the `accuracy_score` metric, which calculates the percentage of correctly classified instances in the test set.  This provides a straightforward measure of the model's overall effectiveness in predicting iris species.  The accuracy score is then printed, giving us a quantifiable measure of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9522397",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
